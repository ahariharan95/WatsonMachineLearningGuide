{"cells": [{"metadata": {}, "cell_type": "markdown", "source": "# Online and Batch Deployment/Scoring in CP4D with WML Python Client\n<br>\n\n* The purpose of this notebook is to demo how to <b>DEPLOY</b> and <b>SCORE</b> your ML Model using the WML Python Client.\n* An <b>XGBOOST</b> model trained on the <b>Kaggle Iris Dataseta</b> is deployed, and scored via <b>Batch and Online</b> methods.\n* Whether you are on a Watson Studio, Jupyter, or local DE, simply import the Watson ML Client library and bring your models to life!\n\n<br> <b>*** Please Note:</b> There are several ways to deploy models on Watson ML. We are focusing on the 'Python Client' method. Other methods are in the watson-machine-learning-client documentation\n\n### Notebook Layout\n* <b>Section 1: Packages and EDA </b> \n* <b>Section 2: Model Training and Building </b> \n* <b>Section 3: WML Client Instantiation </b>\n<br>\n&ensp; <b>3a:</b> Enable User Authentication for CP4D on IBM Cloud Private (ICP) \n<br>\n&ensp; <b>3b:</b> Authenticate and Create WML Python Client Object \n* <b>Section 4: Deployments </b>\n<br>\n&ensp; <b>4a:</b> Create and/or set Deployment Space\n<br>\n&ensp; <b>4b:</b> Online Deployment\n<br>\n&ensp; <b>4c:</b> Batch Deployment\n* <b>Section 5: Scoring </b> \n<br>\n&ensp; <b>5a:</b> Online Scoring - Using REST API Endpoint\n<br>\n&ensp; <b>5b:</b> Online Scoring - Using WML Python Client\n<br>\n&ensp; <b>5c:</b> Batch Scoring\n\n\n### Sources\n* <a href=\"https://www.kaggle.com/uciml/iris#Iris.csv\">KAGGLE IRIS DATASET</a>  Includes three iris species with 50 samples each as well as some properties about each flower.\n* <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-authentication.html\">WML Auth INFO</a> The 'Authentication' overview section of the Watson Machine Learning info on IBM CLOUD Website.\n* <a href=\"https://dataplatform.cloud.ibm.com/docs/content/wsj/analyze-data/ml-deploy_new.html?audience=wdp\">WML Deployment GEN INFO</a>  The 'Deployment' overview section of the Watson Machine Learning info on IBM CLOUD Website.\n* <a href=\"https://matplotlib.org/\">WML Deployment DOCS</a>  the watson-machine-learning-client documentation.\n* <a href=\"https://matplotlib.org/\">WML Deployment V4 DOCS</a>  the watson-machine-learning-client_v4 documentation. More detailed and developer orientated documentation.\n"}, {"metadata": {}, "cell_type": "markdown", "source": "## Section 1: Packages and EDA\n\n<br>\nHere are some quick summary statistics of the Iris Dataset:\n\n* <b>Columns</b>: Id, SepalLengthCm, SepalWidthCm, PetalLengthCm, PetalWidthCm, Species\n* <b>Observations</b>: 150\n* <b>Classes</b>: Iris-virginica (50), Iris-versicolor (50), Iris-setosa (50)\n\n"}, {"metadata": {}, "cell_type": "code", "source": "import pandas as pd \nimport numpy as np \n\n#Modeling Packages\n!pip install sklearn_pandas\nimport sklearn \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Packges for IAM Access Token \nimport json\nimport requests\nimport base64\nfrom requests.auth import HTTPBasicAuth\nimport time\nimport warnings\n\n#Packages for WML Client\nfrom watson_machine_learning_client import WatsonMachineLearningAPIClient\nimport os", "execution_count": 1, "outputs": [{"output_type": "stream", "text": "Collecting sklearn_pandas\n  Downloading https://files.pythonhosted.org/packages/1f/48/4e1461d828baf41d609efaa720d20090ac6ec346b5daad3c88e243e2207e/sklearn_pandas-1.8.0-py2.py3-none-any.whl\nRequirement already satisfied: scipy>=0.14 in /opt/conda/envs/Python-3.6/lib/python3.6/site-packages (from sklearn_pandas) (1.2.0)\nRequirement already satisfied: scikit-learn>=0.15.0 in /opt/conda/envs/Python-3.6/lib/python3.6/site-packages (from sklearn_pandas) (0.20.3)\nRequirement already satisfied: numpy>=1.6.1 in /opt/conda/envs/Python-3.6/lib/python3.6/site-packages (from sklearn_pandas) (1.15.4)\nRequirement already satisfied: pandas>=0.11.0 in /opt/conda/envs/Python-3.6/lib/python3.6/site-packages (from sklearn_pandas) (0.24.1)\nRequirement already satisfied: pytz>=2011k in /opt/conda/envs/Python-3.6/lib/python3.6/site-packages (from pandas>=0.11.0->sklearn_pandas) (2018.9)\nRequirement already satisfied: python-dateutil>=2.5.0 in /opt/conda/envs/Python-3.6/lib/python3.6/site-packages (from pandas>=0.11.0->sklearn_pandas) (2.7.5)\nRequirement already satisfied: six>=1.5 in /user-home/_global_/python-3 (from python-dateutil>=2.5.0->pandas>=0.11.0->sklearn_pandas) (1.12.0)\nInstalling collected packages: sklearn-pandas\nSuccessfully installed sklearn-pandas-1.8.0\n", "name": "stdout"}]}, {"metadata": {"scrolled": true}, "cell_type": "code", "source": "df = pd.read_csv('/project_data/data_asset/Iris.csv')\ndf.describe() ", "execution_count": 2, "outputs": [{"output_type": "execute_result", "execution_count": 2, "data": {"text/plain": "               Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm\ncount  150.000000     150.000000    150.000000     150.000000    150.000000\nmean    75.500000       5.843333      3.054000       3.758667      1.198667\nstd     43.445368       0.828066      0.433594       1.764420      0.763161\nmin      1.000000       4.300000      2.000000       1.000000      0.100000\n25%     38.250000       5.100000      2.800000       1.600000      0.300000\n50%     75.500000       5.800000      3.000000       4.350000      1.300000\n75%    112.750000       6.400000      3.300000       5.100000      1.800000\nmax    150.000000       7.900000      4.400000       6.900000      2.500000", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Id</th>\n      <th>SepalLengthCm</th>\n      <th>SepalWidthCm</th>\n      <th>PetalLengthCm</th>\n      <th>PetalWidthCm</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>count</th>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n      <td>150.000000</td>\n    </tr>\n    <tr>\n      <th>mean</th>\n      <td>75.500000</td>\n      <td>5.843333</td>\n      <td>3.054000</td>\n      <td>3.758667</td>\n      <td>1.198667</td>\n    </tr>\n    <tr>\n      <th>std</th>\n      <td>43.445368</td>\n      <td>0.828066</td>\n      <td>0.433594</td>\n      <td>1.764420</td>\n      <td>0.763161</td>\n    </tr>\n    <tr>\n      <th>min</th>\n      <td>1.000000</td>\n      <td>4.300000</td>\n      <td>2.000000</td>\n      <td>1.000000</td>\n      <td>0.100000</td>\n    </tr>\n    <tr>\n      <th>25%</th>\n      <td>38.250000</td>\n      <td>5.100000</td>\n      <td>2.800000</td>\n      <td>1.600000</td>\n      <td>0.300000</td>\n    </tr>\n    <tr>\n      <th>50%</th>\n      <td>75.500000</td>\n      <td>5.800000</td>\n      <td>3.000000</td>\n      <td>4.350000</td>\n      <td>1.300000</td>\n    </tr>\n    <tr>\n      <th>75%</th>\n      <td>112.750000</td>\n      <td>6.400000</td>\n      <td>3.300000</td>\n      <td>5.100000</td>\n      <td>1.800000</td>\n    </tr>\n    <tr>\n      <th>max</th>\n      <td>150.000000</td>\n      <td>7.900000</td>\n      <td>4.400000</td>\n      <td>6.900000</td>\n      <td>2.500000</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "code", "source": "df.Species.value_counts()", "execution_count": 3, "outputs": [{"output_type": "execute_result", "execution_count": 3, "data": {"text/plain": "Iris-versicolor    50\nIris-setosa        50\nIris-virginica     50\nName: Species, dtype: int64"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Section 2: Model Training and Building\n\n* <b>Data Transformations:</b> The dependent variable, Species, is transformed with <b>LabelEncoder</b>. Classes are 0,1,2 for Iris-virginica, Iris-versicolor, and Iris-setosa respectively. \n* <b>Estimator:</b> <b>XGBOOST</b> classifier. There is no parameter tuning. \n* <b>Results:</b> 93% global accuracy.\n\n<br> <b>*** Please Note:</b> This notebook focuses on deployments, not model building/tuning. "}, {"metadata": {}, "cell_type": "code", "source": "spec_encode = LabelEncoder().fit(df.Species)\ndf['Species'] = spec_encode.transform(df.Species)", "execution_count": 4, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "X = df.drop(['Id','Species'], axis = 1)\ny = df.Species\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)", "execution_count": 5, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "random_forest = RandomForestClassifier()\nmodel= random_forest.fit( X_train, y_train )", "execution_count": 6, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# call model.predict() on your X_test data to make a set of test predictions\ny_prediction = model.predict( X_test )\n# test your predictions using sklearn.classification_report()\nreport = sklearn.metrics.classification_report( y_test, y_prediction )\n# and print the report\nprint(report)", "execution_count": 7, "outputs": [{"output_type": "stream", "text": "              precision    recall  f1-score   support\n\n           0       1.00      1.00      1.00        10\n           1       0.82      0.90      0.86        10\n           2       0.89      0.80      0.84        10\n\n   micro avg       0.90      0.90      0.90        30\n   macro avg       0.90      0.90      0.90        30\nweighted avg       0.90      0.90      0.90        30\n\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Section 3: WML Client Instantiation\n"}, {"metadata": {}, "cell_type": "markdown", "source": "### 3a: Generate IBM Identity Access Management (IAM) Token for IBM Cloud Private (ICP)\n\n* You need an IAM token to instantiate a Python Client Object\n* <b>Inputs:</b> Username, password, and url **(or IP, port pair)** of your CP4D cluster <br> \n&emsp; If you are in the CP4D instance, calling **os.environ['RUNTIME_ENV_APSX_URL']** will return the url <br>\n&emsp; If you are not in a CP4D instance, the URL can be found on the **'Lets Get Stared'** page <br>\n&emsp; **OR** If you are not in a CP4D instance, the URL is also the ip, port pair combo. **Ex: https://< xyz-web-or-ip >:< port number >**\n<br> \n<b>*** Please Note:</b> This generates an IAM token for <b>ICP.</b> The process is nuanced for IBM Public Cloud. You would need an API Key. Refer to documentation for more info. "}, {"metadata": {}, "cell_type": "code", "source": "CREDENTIALS = {\n                      \"username\": 'xyz',\n                      \"password\": \"abc\",\n                      # address should be replaced with ip, port pair to be used in scripts outside ICP\n                      \"url\": 'https://<ip>:<port-number>'\n                   }\n\n\ndef generate_access_token():\n    headers={}\n    headers[\"Accept\"] = \"application/json\"\n    auth = HTTPBasicAuth(CREDENTIALS[\"username\"], CREDENTIALS[\"password\"])\n    \n    ICP_TOKEN_URL= CREDENTIALS[\"url\"] + \"/v1/preauth/validateAuth\"\n    \n    response = requests.get(ICP_TOKEN_URL, headers=headers, auth=auth, verify=False)\n    json_data = response.json()\n    icp_access_token = json_data['accessToken']\n    return icp_access_token\n\ntoken = generate_access_token()", "execution_count": 14, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "### 3b: Authenticate and Create WML Python Client Object \n\n* Once you have your IAM token, you can create a WML Python Client Object. \n* <b>INPUTS:</b> \n<br>\n&ensp; <b>Token:</b> IAM token obtained in step 3A\n<br>\n&ensp; <b>Instance Id:</b> Set to 'ICP' or 'Openshift' depending on what platform Watson Studio is running on.\n<br>\n&ensp; <b>Url:</b> IP, port pair of where Watson Studio is located.\n<br>\n&emsp; This can be found calling <b>os.environ['RUNTIME_ENV_APSX_URL']</b> if you are in ICP. \n<br>\n&emsp; You can also use the URL of the Watson Studio instance if you are in ICP (this was done in 3a).  \n<br>\n&ensp; <b>Version:</b> In our case, it is '2.5.0'. \n<br>\n&emsp; <b>IBM CP4D 3.0 is days away of being released.</b> In that case, version would be set to '3.0.0'.\n<br><br>\n<b>*** Please Note:</b> This generates a client object for <b>ICP.</b> The process is nuanced for IBM Public Cloud. You would need an API Key and WML Instance ID. Refer to documentation for more info. "}, {"metadata": {}, "cell_type": "code", "source": "#token = os.environ['USER_ACCESS_TOKEN']\nurl= 'os.environ['RUNTIME_ENV_APSX_URL']'\n\nwml_credentials = {\n   \"token\": token,\n   \"instance_id\" : \"openshift\",\n   \"url\": url,\n   \"version\": \"2.5.0\"\n}\n\nwml_client = WatsonMachineLearningAPIClient(wml_credentials)", "execution_count": 16, "outputs": []}, {"metadata": {}, "cell_type": "markdown", "source": "## Section 4: Deployments"}, {"metadata": {}, "cell_type": "markdown", "source": "### 4a: Create and/or Set Deployment Space\n\n* Setting a default Deployment Space or Project ID is <b>the first and mandatory step </b> in CP4D. This tells the client from where to push/pull information. \n* Because the focus is Deployments, a Deployment Space ID will be set. \n\n"}, {"metadata": {}, "cell_type": "code", "source": "SPACE_NAME = \"IRIS_MODEL_SPACE\"", "execution_count": 17, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# If Space with same name, set new ID, if not, create new ID for project \nspace_name = SPACE_NAME\nspaces = wml_client.spaces.get_details()['resources']\nspace_id = None\nfor space in spaces:\n    if space['entity']['name'] == space_name:\n        space_id = space[\"metadata\"][\"guid\"]\nif space_id is None:\n    space_id = wml_client.spaces.store(\n        meta_props={wml_client.spaces.ConfigurationMetaNames.NAME: space_name})[\"metadata\"][\"guid\"]\nwml_client.set.default_space(space_id)", "execution_count": 18, "outputs": [{"output_type": "execute_result", "execution_count": 18, "data": {"text/plain": "'SUCCESS'"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### 4b: Online Deployment\n\n&emsp; <b>TRAIN/BUILD</b> MODEL --> <b>STORE MODEL</b> IN DEPLOYMENT SPACE (CREATE ID) --> <b>DEPLOY MODEL</b> FROM DEPLOYMENT SPACE (CREATE ID) \n\n* Online and Batch deployment cycles are identical. A trained model is stored (in the deployment space) and subsequently deployed.\n* For Online Deployments: \n<br>\n&emsp; <b>1.</b> Model and deployment names are set <br>\n&emsp; <b>2.</b> Deployment space checked for any existing deployments set to what was named in Step1. If so, deployment and associated model are deleted. New ones are set.<br>\n&emsp; <b>3.</b> Model is pushed and stored in deployment space. Model ID created.<br> \n&emsp; <b>4.</b> Model is deployed from deployment space. Deployment ID created. <br>"}, {"metadata": {}, "cell_type": "code", "source": "MODEL_NAME = 'IRIS_RF_Online'\ndeployment_name = 'IRIS_RF_Online_Deployment'", "execution_count": 19, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Remove any deployments and associated models with same name\ndeployment_details = wml_client.deployments.get_details()\nfor deployment in deployment_details['resources']:\n    deployment_id = deployment['metadata']['guid']\n    model_id = deployment['entity']['asset']['href'].split('/')[3].split('?')[0]\n    if deployment['entity']['name'] == deployment_name:\n        print('Deleting deployment id', deployment_id)\n        wml_client.deployments.delete(deployment_id)\n        print('Deleting model id', model_id)\n        wml_client.repository.delete(model_id)", "execution_count": 20, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#Save Model to Space \n\nspace_metadata = {\n    wml_client.repository.ModelMetaNames.NAME: MODEL_NAME,\n    wml_client.repository.ModelMetaNames.TYPE: \"scikit-learn_0.20\",\n    wml_client.repository.ModelMetaNames.RUNTIME_UID: \"scikit-learn_0.20-py3\",\n    wml_client.repository.ModelMetaNames.TAGS: [{'value' : 'iris_online_tag'}],\n    wml_client.repository.ModelMetaNames.SPACE_UID: space_id\n}\n\nstored_model_details = wml_client.repository.store_model(model=model, meta_props=space_metadata)", "execution_count": 21, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Deploy the model\n\nmeta_props = {\n    wml_client.deployments.ConfigurationMetaNames.NAME: deployment_name,\n    wml_client.deployments.ConfigurationMetaNames.TAGS : [{'value' : 'iris_online_deployment_tag'}],\n    wml_client.deployments.ConfigurationMetaNames.ONLINE: {}\n}\n\nmodel_uid = stored_model_details[\"metadata\"][\"guid\"]\nwml_client.deployments.create(artifact_uid=model_uid, meta_props=meta_props)", "execution_count": 22, "outputs": [{"output_type": "stream", "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: 'b0b18f80-a2f4-4691-9eab-879779c868c5' started\n\n#######################################################################################\n\n\ninitializing....................................................\nready\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='8bfb500c-06ce-4e41-9d83-b78478cb72ae'\n------------------------------------------------------------------------------------------------\n\n\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 22, "data": {"text/plain": "{'metadata': {'parent': {'href': ''},\n  'guid': '8bfb500c-06ce-4e41-9d83-b78478cb72ae',\n  'modified_at': '',\n  'created_at': '2020-05-09T00:32:18.475Z',\n  'href': '/v4/deployments/8bfb500c-06ce-4e41-9d83-b78478cb72ae'},\n 'entity': {'name': 'IRIS_RF_Online_Deployment',\n  'custom': {},\n  'online': {},\n  'description': '',\n  'tags': [{'value': 'iris_online_deployment_tag', 'description': ''}],\n  'space': {'href': '/v4/spaces/8b9e1282-94fc-4f5d-9a81-af2992c4ec27'},\n  'status': {'state': 'ready',\n   'online_url': {'url': 'https://zen-cpd-zen.apps.lb.development01.csplab.local/v4/deployments/8bfb500c-06ce-4e41-9d83-b78478cb72ae/predictions'}},\n  'asset': {'href': '/v4/models/b0b18f80-a2f4-4691-9eab-879779c868c5?space_id=8b9e1282-94fc-4f5d-9a81-af2992c4ec27'},\n  'auto_redeploy': False}}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### 4c: Batch Deployment\n\n* Online and Batch deployment cycles are identical. A trained model is stored (in the deployment space) and subsequently deployed.\n* For Batch Deployments: \n<br>\n&emsp; <b>1.</b> Model and deployment names are set <br>\n&emsp; <b>2.</b> Deployment space checked for any existing deployments set to what was named in Step1. If so, deployment and associated model are deleted. New ones are set.<br>\n&emsp; <b>3.</b> Model is pushed and stored in deployment space. Model ID created.<br> \n&emsp; <b>4.</b> Model is deployed from deployment space. Deployment ID created. <br>"}, {"metadata": {}, "cell_type": "code", "source": "MODEL_NAME = 'IRIS_RF_Batch'\ndeployment_name = 'IRIS_RF_Batch_Deployment'", "execution_count": 23, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Remove any deployments and associated models with same name\n\ndeployment_details = wml_client.deployments.get_details()\nfor deployment in deployment_details['resources']:\n    deployment_id = deployment['metadata']['guid']\n    model_id = deployment['entity']['asset']['href'].split('/')[3].split('?')[0]\n    if deployment['entity']['name'] == deployment_name:\n        print('Deleting deployment id', deployment_id)\n        wml_client.deployments.delete(deployment_id)\n        print('Deleting model id', model_id)\n        wml_client.repository.delete(model_id)", "execution_count": 24, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Save model to Space\n\nspace_metadata = {\n    wml_client.repository.ModelMetaNames.NAME: MODEL_NAME,\n    wml_client.repository.ModelMetaNames.TYPE: \"scikit-learn_0.20\",\n    wml_client.repository.ModelMetaNames.RUNTIME_UID: \"scikit-learn_0.20-py3\",\n    wml_client.repository.ModelMetaNames.TAGS: [{'value' : 'iris_batch_tag'}],\n    wml_client.repository.ModelMetaNames.SPACE_UID: space_id\n}\n\nstored_model_details = wml_client.repository.store_model(model=model, meta_props=space_metadata)", "execution_count": 25, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "# Deploy the model\n\nmeta_props = {\n    wml_client.deployments.ConfigurationMetaNames.NAME: deployment_name,\n    wml_client.deployments.ConfigurationMetaNames.TAGS : [{'value' : 'iris_batch_deployment_tag'}],\n    wml_client.deployments.ConfigurationMetaNames.BATCH: {},\n    wml_client.deployments.ConfigurationMetaNames.COMPUTE: {\n        \"name\": \"S\",\n         \"nodes\": 1\n     }\n }\n\nmodel_uid = stored_model_details[\"metadata\"][\"guid\"]\nwml_client.deployments.create(artifact_uid=model_uid, meta_props=meta_props)", "execution_count": 26, "outputs": [{"output_type": "stream", "text": "\n\n#######################################################################################\n\nSynchronous deployment creation for uid: '0f362e0e-8548-4ae7-9eb9-6986096ea881' started\n\n#######################################################################################\n\n\nready.\n\n\n------------------------------------------------------------------------------------------------\nSuccessfully finished deployment creation, deployment_uid='a20e9cb3-46ad-4e13-a1fa-ba6162678c49'\n------------------------------------------------------------------------------------------------\n\n\n", "name": "stdout"}, {"output_type": "execute_result", "execution_count": 26, "data": {"text/plain": "{'metadata': {'parent': {'href': ''},\n  'guid': 'a20e9cb3-46ad-4e13-a1fa-ba6162678c49',\n  'modified_at': '',\n  'created_at': '2020-05-09T00:37:31.878Z',\n  'href': '/v4/deployments/a20e9cb3-46ad-4e13-a1fa-ba6162678c49'},\n 'entity': {'name': 'IRIS_RF_Batch_Deployment',\n  'custom': {},\n  'description': '',\n  'tags': [{'value': 'iris_batch_deployment_tag', 'description': ''}],\n  'compute': {'name': 'S', 'nodes': 1},\n  'batch': {},\n  'space': {'href': '/v4/spaces/8b9e1282-94fc-4f5d-9a81-af2992c4ec27'},\n  'status': {'state': 'ready'},\n  'asset': {'href': '/v4/models/0f362e0e-8548-4ae7-9eb9-6986096ea881?space_id=8b9e1282-94fc-4f5d-9a81-af2992c4ec27'},\n  'auto_redeploy': False}}"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Section 5: Scoring"}, {"metadata": {}, "cell_type": "markdown", "source": "### 5a: Online Scoring - Using REST API Endpoint\n\n* An Online Deployment can be accessed through the <b>Python Client</b>, <b>Command Line Interface (CLI)</b>, or <b>REST API.</b><br><br>\n* For Online Scoring through <b>REST API: </b>\n<br>\n&emsp; <b>1.</b> Define online deployment name and retrieve ID (your online model should have already been deployed).  <br>\n&emsp; <b>2.</b> Retrieve the Online URL by either constructing the Endpoint/URL or calling wml_client.deployments.get_details(< model id >). <br>\n&emsp; &emsp; &emsp; The URL construction in our case is <b>'< url where model is deployed >/4/deployment< model id >/predictions'</b> <br>\n&emsp; &emsp; &emsp; The scoring Endpoint/URL can also be found by <b> clicking </b> on the deployment  </b> <br>\n&emsp; <b>3.</b> Construct authentication header (using IAM Token), scoring payload, and score results<br> \n&emsp; &emsp; &emsp; Boiler Code is used for the authentication header, payload constructer, and scoring. This can be found in the documentation.<br> \n&emsp; &emsp; &emsp;<b>***</b> ML Token is the IAM token defined in <b>Section 3</b><br> \n&emsp; &emsp; &emsp;<b>***</b> WML is a stickler for the payload input. Valid payloads for scoring are list of <b>values, pandas or numpy dataframes.</b><br>\n&emsp; &emsp; &emsp;<b>***</b> Online score by running <b>requests.post(< scoring url > , < scoring payload > , verify = False )</b><br>\n&emsp; <b>4.</b> Compile output. Compiling output is at user discretion."}, {"metadata": {}, "cell_type": "code", "source": "#1. Setting and finding deployment name \nonline_deployment_name = 'IRIS_RF_Online_Deployment'\nonline_deployment_id = None\n\nfor dep in wml_client.deployments.get_details()['resources']:\n    if dep['entity']['name'] == online_deployment_name:\n        print('found id!')\n        online_deployment_id = dep['metadata']['guid']    ### HERE WE ARE FINDING CORRESPONDING DEPLOYMENT ID \n        break\nif online_deployment_id == None: print('did not find id')", "execution_count": 27, "outputs": [{"output_type": "stream", "text": "found id!\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "# Creating dummy score data\nsep_length = (8 - .8) * np.random.random_sample((50,)) + .8\nsep_width = (5 - .4) * np.random.random_sample((50,)) + .4\npet_length = (7 - 1.7) * np.random.random_sample((50,)) + 1.7\npet_width  = (3 - .7) * np.random.random_sample((50,)) + .7\n\nscore_data = pd.DataFrame({'SepalLengthCm':sep_length,'SepalWidthCm':sep_width,'PetalLengthCm':pet_length,'PetalWidthCm':pet_width})", "execution_count": 28, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#2. Constructing scoring URL \ndef get_online_deployment_href(asset_id, url):\n    DATA_ASSET = u'{}/v4/deployments/{}/predictions'\n    return DATA_ASSET.format(url,asset_id)\n\niris_online_href = get_online_deployment_href(online_deployment_id,CREDENTIALS['url'])", "execution_count": 29, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#3. Construct authentication header, scoring payload, and score results \nmltoken = token\nheader = {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + mltoken}\npayload_scoring = {\"input_data\": [{\"fields\": score_data.columns.tolist(), \"values\": score_data.values.tolist()}]}\nresponse_scoring = requests.post(iris_online_href , json=payload_scoring, headers= header,verify = False)\nonline_scoring_results = json.loads(response_scoring.text)", "execution_count": 30, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "#4. Compile Results\nscore_result_columns = online_scoring_results['predictions'][0]['fields']\nscore_result_data =online_scoring_results['predictions'][0]['values']\n\nonline_result_df = score_data.copy()\nonline_result_df['Predictions'] ,online_result_df['Probability'] = [x[0] for x in score_result_data ], [x[1] for x in score_result_data ]\nonline_result_df['Predictions'] = spec_encode.inverse_transform(online_result_df['Predictions'])", "execution_count": 31, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "online_result_df.sample(5)", "execution_count": 32, "outputs": [{"output_type": "execute_result", "execution_count": 32, "data": {"text/plain": "    SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Predictions  \\\n19       2.795668      2.550230       2.076833      1.393320  Iris-versicolor   \n31       7.955788      1.422871       3.827253      2.380504  Iris-versicolor   \n0        7.676480      0.519356       6.642910      1.225585   Iris-virginica   \n9        6.826764      1.680009       1.842966      1.430981      Iris-setosa   \n33       7.456475      1.389737       6.758010      2.551476   Iris-virginica   \n\n        Probability  \n19  [0.4, 0.5, 0.1]  \n31  [0.0, 0.5, 0.5]  \n0   [0.0, 0.0, 1.0]  \n9   [0.5, 0.4, 0.1]  \n33  [0.0, 0.0, 1.0]  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SepalLengthCm</th>\n      <th>SepalWidthCm</th>\n      <th>PetalLengthCm</th>\n      <th>PetalWidthCm</th>\n      <th>Predictions</th>\n      <th>Probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>19</th>\n      <td>2.795668</td>\n      <td>2.550230</td>\n      <td>2.076833</td>\n      <td>1.393320</td>\n      <td>Iris-versicolor</td>\n      <td>[0.4, 0.5, 0.1]</td>\n    </tr>\n    <tr>\n      <th>31</th>\n      <td>7.955788</td>\n      <td>1.422871</td>\n      <td>3.827253</td>\n      <td>2.380504</td>\n      <td>Iris-versicolor</td>\n      <td>[0.0, 0.5, 0.5]</td>\n    </tr>\n    <tr>\n      <th>0</th>\n      <td>7.676480</td>\n      <td>0.519356</td>\n      <td>6.642910</td>\n      <td>1.225585</td>\n      <td>Iris-virginica</td>\n      <td>[0.0, 0.0, 1.0]</td>\n    </tr>\n    <tr>\n      <th>9</th>\n      <td>6.826764</td>\n      <td>1.680009</td>\n      <td>1.842966</td>\n      <td>1.430981</td>\n      <td>Iris-setosa</td>\n      <td>[0.5, 0.4, 0.1]</td>\n    </tr>\n    <tr>\n      <th>33</th>\n      <td>7.456475</td>\n      <td>1.389737</td>\n      <td>6.758010</td>\n      <td>2.551476</td>\n      <td>Iris-virginica</td>\n      <td>[0.0, 0.0, 1.0]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### 5b: Online Scoring - Using WML Python Client\n\n* An Online Deployment can be accessed through the <b>Python Client</b>, <b>Command Line Interface (CLI)</b>, or <b>REST API.</b><br><br>\n* For Online Scoring through <b>PYTHON CLIENT: </b>\n<br>\n&emsp; <b>1.</b> Define online deployment name and retrieve ID (your online model should have already been deployed).  <br>\n&emsp; <b>2.</b> Construct the scoring payload, and score results<br> \n&emsp; &emsp; &emsp; Boiler Code is used for the scoring. This can be found in the documentation.<br> \n&emsp; &emsp; &emsp;<b>***</b> WML is a stickler for the payload input. Valid payloads for scoring are list of <b>values, pandas or numpy dataframes.</b><br>\n&emsp; &emsp; &emsp;<b>***</b> Online score by running <b> wml_client.deployments.score(< deployment id > , < scoring payload >)</b><br>\n&emsp; <b>4.</b> Compile output. Compiling output is at user discretion."}, {"metadata": {}, "cell_type": "code", "source": "online_deployment_name = 'IRIS_RF_Online_Deployment'\nonline_deployment_id = None\n\nfor dep in wml_client.deployments.get_details()['resources']:\n    if dep['entity']['name'] == online_deployment_name:\n        print('found id!')\n        online_deployment_id = dep['metadata']['guid']    ### HERE WE ARE FINDING CORRESPONDING DEPLOYMENT ID \n        break\nif online_deployment_id == None: print('did not find id')\n", "execution_count": 33, "outputs": [{"output_type": "stream", "text": "found id!\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "scoring_payload = {wml_client.deployments.ScoringMetaNames.INPUT_DATA: [{'fields': score_data.columns.tolist(), 'values': score_data.values.tolist()  }]}\n", "execution_count": 34, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "online_scoring_results = wml_client.deployments.score(online_deployment_id, scoring_payload)", "execution_count": 35, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "score_result_columns = online_scoring_results['predictions'][0]['fields']\nscore_result_data =online_scoring_results['predictions'][0]['values']\n\nonline_result_df = score_data.copy()\nonline_result_df['Predictions'] ,online_result_df['Probability'] = [x[0] for x in score_result_data ], [x[1] for x in score_result_data ]\nonline_result_df['Predictions'] = spec_encode.inverse_transform(online_result_df['Predictions'])\n\nonline_result_df.sample(5)", "execution_count": 36, "outputs": [{"output_type": "execute_result", "execution_count": 36, "data": {"text/plain": "    SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm      Predictions  \\\n0        7.676480      0.519356       6.642910      1.225585   Iris-virginica   \n1        7.641686      0.607364       3.046193      1.548297  Iris-versicolor   \n24       4.964359      0.671011       5.711646      2.245724   Iris-virginica   \n47       6.113861      0.884578       5.264106      1.901249   Iris-virginica   \n32       6.426823      1.716275       3.720906      0.973433  Iris-versicolor   \n\n        Probability  \n0   [0.0, 0.0, 1.0]  \n1   [0.0, 0.8, 0.2]  \n24  [0.0, 0.1, 0.9]  \n47  [0.0, 0.0, 1.0]  \n32  [0.0, 0.9, 0.1]  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SepalLengthCm</th>\n      <th>SepalWidthCm</th>\n      <th>PetalLengthCm</th>\n      <th>PetalWidthCm</th>\n      <th>Predictions</th>\n      <th>Probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>7.676480</td>\n      <td>0.519356</td>\n      <td>6.642910</td>\n      <td>1.225585</td>\n      <td>Iris-virginica</td>\n      <td>[0.0, 0.0, 1.0]</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>7.641686</td>\n      <td>0.607364</td>\n      <td>3.046193</td>\n      <td>1.548297</td>\n      <td>Iris-versicolor</td>\n      <td>[0.0, 0.8, 0.2]</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>4.964359</td>\n      <td>0.671011</td>\n      <td>5.711646</td>\n      <td>2.245724</td>\n      <td>Iris-virginica</td>\n      <td>[0.0, 0.1, 0.9]</td>\n    </tr>\n    <tr>\n      <th>47</th>\n      <td>6.113861</td>\n      <td>0.884578</td>\n      <td>5.264106</td>\n      <td>1.901249</td>\n      <td>Iris-virginica</td>\n      <td>[0.0, 0.0, 1.0]</td>\n    </tr>\n    <tr>\n      <th>32</th>\n      <td>6.426823</td>\n      <td>1.716275</td>\n      <td>3.720906</td>\n      <td>0.973433</td>\n      <td>Iris-versicolor</td>\n      <td>[0.0, 0.9, 0.1]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "### 5c: Batch Scoring\n\n* Batch scoring is extremely useful when you are setting up a pipeline that needs to score large amounts of data, at time intervals, or pulls/pushes into databases.<br>\n* Supported databses are Cloud Object Storage buckets (COS), DB2, PostgreSQL. \n* In the example, the scoring set is the same as the online datasets. This can be replaced by Database Connection,local csv files, etc. <br><br>\n* For Batch Scoring through <b>PYTHON CLIENT: </b><br>\n&emsp; <b>1.</b> Define batch deployment name and retrieve ID (your batch model should have already been deployed).<br>\n&emsp; <b>2.</b> Construct the scoring payload, and score results<br> \n&emsp; &emsp; &emsp; Boiler Code is used for the scoring. This can be found in the documentation.<br> \n&emsp; &emsp; &emsp;<b>***</b> WML is a stickler for the payload input. Valid payloads for scoring are list of <b>values, pandas or numpy dataframes.</b>\n<br>\n&emsp; &emsp; &emsp;<b>***</b> Batch score by running <b>client.deployents.create_job(< deployment id > , < scoring payload >)</b>\n<br>\n&emsp; &emsp; &emsp;<b>***</b> States of a job are 'queued'-->'running'-->'completed' or 'failed'</b>\n<br>\n&emsp; <b>4.</b> Compile output. Compiling output is at user discretion."}, {"metadata": {}, "cell_type": "code", "source": "#1. Get the batch Deployment ID - Will be used for creating batch job for scoring \nbatch_deployment_name = 'IRIS_RF_Batch_Deployment'\nbatch_deployment_id = None\n\nfor dep in wml_client.deployments.get_details()['resources']:\n    if dep['entity']['name'] == batch_deployment_name:\n        print('found id!')\n        batch_deployment_id = dep['metadata']['guid']    ### HERE WE ARE FINDING CORRESPONDING DEPLOYMENT ID \n        break\nif batch_deployment_id == None: print('did not find id') ", "execution_count": 37, "outputs": [{"output_type": "stream", "text": "found id!\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "#Create batch scoring job *NOTE*- Jobs can only be created for batch deployments \nbatch_scoring_job = wml_client.deployments.create_job(batch_deployment_id, scoring_payload)\nbatch_scoring_id = batch_scoring_job['metadata']['guid']", "execution_count": 38, "outputs": []}, {"metadata": {}, "cell_type": "code", "source": "##Cell will stop running once model job is complete \nstate = wml_client.deployments.get_job_status(batch_scoring_id)['state']\nwhile state !='completed':\n    state = wml_client.deployments.get_job_status(batch_scoring_id)['state']\nprint('model scored!')", "execution_count": 39, "outputs": [{"output_type": "stream", "text": "model scored!\n", "name": "stdout"}]}, {"metadata": {}, "cell_type": "code", "source": "batch_scoring_results = wml_client.deployments.get_job_details(batch_scoring_id)\n\nscore_result_columns = batch_scoring_results['entity']['scoring']['predictions'][0]['fields']\nscore_result_data =batch_scoring_results['entity']['scoring']['predictions'][0]['values']\n\nbatch_result_df = score_data.copy()\nbatch_result_df['Predictions'] ,batch_result_df['Probability'] = [x[0] for x in score_result_data ], [x[1] for x in score_result_data ]\n\nbatch_result_df.sample(5)", "execution_count": 40, "outputs": [{"output_type": "execute_result", "execution_count": 40, "data": {"text/plain": "    SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  Predictions  \\\n23       1.746538      2.051380       4.656183      0.729098            0   \n48       4.045124      3.709616       4.739772      2.889168            2   \n24       4.964359      0.671011       5.711646      2.245724            2   \n19       2.795668      2.550230       2.076833      1.393320            1   \n30       2.975255      4.988337       6.514303      2.189696            2   \n\n        Probability  \n23  [0.5, 0.3, 0.2]  \n48  [0.2, 0.3, 0.5]  \n24  [0.0, 0.1, 0.9]  \n19  [0.4, 0.5, 0.1]  \n30  [0.2, 0.0, 0.8]  ", "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>SepalLengthCm</th>\n      <th>SepalWidthCm</th>\n      <th>PetalLengthCm</th>\n      <th>PetalWidthCm</th>\n      <th>Predictions</th>\n      <th>Probability</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>23</th>\n      <td>1.746538</td>\n      <td>2.051380</td>\n      <td>4.656183</td>\n      <td>0.729098</td>\n      <td>0</td>\n      <td>[0.5, 0.3, 0.2]</td>\n    </tr>\n    <tr>\n      <th>48</th>\n      <td>4.045124</td>\n      <td>3.709616</td>\n      <td>4.739772</td>\n      <td>2.889168</td>\n      <td>2</td>\n      <td>[0.2, 0.3, 0.5]</td>\n    </tr>\n    <tr>\n      <th>24</th>\n      <td>4.964359</td>\n      <td>0.671011</td>\n      <td>5.711646</td>\n      <td>2.245724</td>\n      <td>2</td>\n      <td>[0.0, 0.1, 0.9]</td>\n    </tr>\n    <tr>\n      <th>19</th>\n      <td>2.795668</td>\n      <td>2.550230</td>\n      <td>2.076833</td>\n      <td>1.393320</td>\n      <td>1</td>\n      <td>[0.4, 0.5, 0.1]</td>\n    </tr>\n    <tr>\n      <th>30</th>\n      <td>2.975255</td>\n      <td>4.988337</td>\n      <td>6.514303</td>\n      <td>2.189696</td>\n      <td>2</td>\n      <td>[0.2, 0.0, 0.8]</td>\n    </tr>\n  </tbody>\n</table>\n</div>"}, "metadata": {}}]}, {"metadata": {}, "cell_type": "markdown", "source": "## Developed by IBM CPAT team:\n\nEmilio Fiallos - Data Scientist               "}], "metadata": {"kernelspec": {"name": "python3", "display_name": "Python 3.6", "language": "python"}, "language_info": {"name": "python", "version": "3.6.8", "mimetype": "text/x-python", "codemirror_mode": {"name": "ipython", "version": 3}, "pygments_lexer": "ipython3", "nbconvert_exporter": "python", "file_extension": ".py"}}, "nbformat": 4, "nbformat_minor": 1}